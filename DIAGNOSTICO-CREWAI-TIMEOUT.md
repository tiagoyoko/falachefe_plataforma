# Diagn√≥stico: CrewAI Timeout no Servidor Hetzner

## üîç Problema Identificado

O servidor CrewAI Flask est√° recebendo requisi√ß√µes mas **n√£o respondendo** devido a timeout na inicializa√ß√£o do CrewAI.

## üìä Evid√™ncias

### 1. Health Check
```json
{
  "status": "healthy",
  "crew_initialized": false,  // ‚ùå CrewAI N√ÉO inicializado
  "uazapi_configured": true,
  "qstash_configured": false
}
```

### 2. Teste de Requisi√ß√£o
```bash
curl -X POST https://api.falachefe.app.br/process \
  -H "Content-Type: application/json" \
  -d '{"message": "teste", "userId": "...", "phoneNumber": "..."}'
  
# Resultado: TIMEOUT ap√≥s 30 segundos
```

### 3. Logs do Webhook (Vercel)
```
‚úÖ Payload enviado corretamente:
{
  "message": "Oi, quero criar um plano de carreira...",
  "userId": "2f16ae84-c5df-47dd-a81f-e83b8de315da",
  "phoneNumber": "5511994066248",
  "context": {...}
}

‚ùå SEM RESPOSTA do CrewAI
```

## üêõ Causa Raiz

O servidor Flask usa **lazy loading** do CrewAI:

```python
# api_server.py linha 36-46
crew_instance = None

def get_crew():
    global crew_instance
    if crew_instance is None:
        print("üöÄ Initializing FalachefeCrew...", file=sys.stderr)
        crew_instance = FalachefeCrew()  # ‚Üê TRAVA AQUI
        print("‚úÖ FalachefeCrew initialized", file=sys.stderr)
    return crew_instance
```

**Problema:**
1. Primeira requisi√ß√£o chega em `/process`
2. Tenta inicializar `FalachefeCrew()`
3. Inicializa√ß√£o demora **> 120 segundos** (timeout do Gunicorn)
4. Gunicorn mata o worker por timeout
5. Pr√≥xima requisi√ß√£o reinicia o ciclo

## ‚öôÔ∏è Configura√ß√£o Atual

```yaml
# docker-compose.yml
GUNICORN_TIMEOUT: 120  # 2 minutos
GUNICORN_WORKERS: 2
GUNICORN_THREADS: 4
```

## üîß Solu√ß√µes Poss√≠veis

### Solu√ß√£o 1: Pr√©-inicializar CrewAI (RECOMENDADO)
Inicializar crew ao startar servidor, n√£o no primeiro request.

```python
# api_server.py
if __name__ == '__main__':
    print("üöÄ Pre-initializing CrewAI...", file=sys.stderr)
    crew_instance = FalachefeCrew()  # Inicializar ANTES de startar Flask
    print("‚úÖ CrewAI ready", file=sys.stderr)
    
    app.start_time = time()
    app.run(host='0.0.0.0', port=port, debug=False)
```

### Solu√ß√£o 2: Aumentar Timeout Gunicorn
```yaml
GUNICORN_TIMEOUT: 300  # 5 minutos
```

### Solu√ß√£o 3: Resposta Ass√≠ncrona
1. Receber requisi√ß√£o
2. Retornar `202 Accepted` imediatamente
3. Processar em background
4. Enviar resposta via webhook callback

### Solu√ß√£o 4: Health Check com Inicializa√ß√£o
```python
@app.route('/health', methods=['GET'])
def health():
    # For√ßar inicializa√ß√£o no health check
    crew = get_crew()
    return jsonify({
        "status": "healthy",
        "crew_initialized": crew is not None
    })
```

## üìù Pr√≥ximos Passos

### Imediato (Solu√ß√£o R√°pida)
1. SSH no servidor Hetzner
2. Aumentar `GUNICORN_TIMEOUT` para 300
3. Reiniciar container CrewAI
4. Testar inicializa√ß√£o

```bash
ssh root@37.27.248.13
cd /opt/falachefe-crewai
nano .env  # GUNICORN_TIMEOUT=300
docker compose restart crewai-api
docker compose logs -f crewai-api  # Ver inicializa√ß√£o
```

### Definitivo (Solu√ß√£o Correta)
1. Modificar `api_server.py` para pr√©-inicializar
2. Testar localmente
3. Deploy com GitHub MCP
4. Validar no Hetzner

## üéØ Solu√ß√£o Implementada

**Escolha:** Solu√ß√£o 1 (Pr√©-inicializar) + Solu√ß√£o 2 (Timeout maior)

### Vantagens
- ‚úÖ Crew pronto ao receber primeira requisi√ß√£o
- ‚úÖ Sem timeout no processamento
- ‚úÖ Performance consistente
- ‚úÖ F√°cil debug

### Desvantagens
- ‚ö†Ô∏è Startup mais lento (ok para produ√ß√£o)
- ‚ö†Ô∏è Requer mais mem√≥ria no boot

---

**Data:** 2025-10-13  
**Severidade:** ALTA (servi√ßo n√£o funcional)  
**Status:** DIAGNOSTICADO - Aguardando implementa√ß√£o

