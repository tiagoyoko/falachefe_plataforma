# üîÑ SOLU√á√ÉO: Cron com Supabase + Upstash Redis

**Data**: 14 de Outubro de 2025  
**Problema**: Limita√ß√µes de Vercel Cron  
**Solu√ß√£o**: Usar Supabase pg_cron para gerenciar filas Redis

---

## üéØ PROBLEMA IDENTIFICADO

### Limita√ß√µes do Vercel Cron

```yaml
Vercel Cron (Hobby/Pro):
  Frequ√™ncia m√≠nima: 1 minuto (mas n√£o recomendado)
  Timeout: 10s (Hobby), 60s (Pro), 300s (Enterprise)
  Execu√ß√µes/dia: Limitadas
  Confiabilidade: M√©dia (cold starts)
  Custo: Conta para Serverless execution time
  
Problemas:
  ‚ùå Timeout muito curto para jobs pesados
  ‚ùå Cold starts podem atrasar execu√ß√£o
  ‚ùå Dif√≠cil debugar falhas
  ‚ùå N√£o h√° retry autom√°tico
  ‚ùå Consome cota de execu√ß√£o
```

### Casos de Uso Afetados

```typescript
// Exemplos de jobs que podem ter problemas:
1. Processar mensagens em lote (CrewAI)
2. Limpeza de dados antigos
3. Sincroniza√ß√£o com APIs externas
4. Envio de notifica√ß√µes agendadas
5. Relat√≥rios di√°rios/semanais
6. Backup de dados
7. Renova√ß√£o de tokens/sess√µes
```

---

## ‚úÖ SOLU√á√ÉO PROPOSTA

### Arquitetura: Supabase pg_cron + Upstash Redis

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        SUPABASE                                  ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL + pg_cron Extension                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Schedule jobs (cron syntax)                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Execute SQL functions                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Confi√°vel (n√£o depende de cold start)                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Timeout: configur√°vel                                  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                            ‚Üì                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Edge Functions (Deno)                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Chamadas via http_request (SQL)                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ L√≥gica customizada                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Retry logic                                            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    UPSTASH REDIS                                 ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚Ä¢ Enfileirar jobs                                              ‚îÇ
‚îÇ  ‚Ä¢ Gerenciar estado                                             ‚îÇ
‚îÇ  ‚Ä¢ Rate limiting                                                ‚îÇ
‚îÇ  ‚Ä¢ Cache                                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    VERCEL (Next.js)                              ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚Ä¢ API Route: /api/cron/process-queue                           ‚îÇ
‚îÇ  ‚Ä¢ Processa jobs da fila Redis                                 ‚îÇ
‚îÇ  ‚Ä¢ Executa l√≥gica de neg√≥cio                                   ‚îÇ
‚îÇ  ‚Ä¢ Atualiza status no Supabase                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üèóÔ∏è IMPLEMENTA√á√ÉO DETALHADA

### Op√ß√£o 1: pg_cron ‚Üí Edge Function ‚Üí Redis (RECOMENDADO)

#### 1.1 Habilitar pg_cron no Supabase

```sql
-- No Supabase SQL Editor
-- pg_cron j√° vem instalado, s√≥ precisa habilitar

-- Verificar extens√£o
SELECT extname, extversion FROM pg_extension WHERE extname = 'pg_cron';

-- Se n√£o estiver instalado (raro):
CREATE EXTENSION IF NOT EXISTS pg_cron;
```

#### 1.2 Criar Edge Function no Supabase

**Arquivo**: `supabase/functions/enqueue-job/index.ts`

```typescript
// Supabase Edge Function (Deno)
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { Redis } from "https://esm.sh/@upstash/redis@1.20.1";

// Configurar Redis
const redis = new Redis({
  url: Deno.env.get('UPSTASH_REDIS_REST_URL')!,
  token: Deno.env.get('UPSTASH_REDIS_REST_TOKEN')!,
});

interface JobPayload {
  type: string;
  data: any;
  priority?: number;
  scheduledFor?: string;
}

serve(async (req) => {
  try {
    // Validar m√©todo
    if (req.method !== 'POST') {
      return new Response('Method not allowed', { status: 405 });
    }

    // Validar secret (seguran√ßa)
    const authHeader = req.headers.get('authorization');
    const secret = Deno.env.get('CRON_SECRET');
    
    if (authHeader !== `Bearer ${secret}`) {
      return new Response('Unauthorized', { status: 401 });
    }

    // Parse payload
    const payload: JobPayload = await req.json();

    // Valida√ß√µes
    if (!payload.type || !payload.data) {
      return new Response('Invalid payload', { status: 400 });
    }

    console.log('üì® Enqueueing job:', payload.type);

    // Enfileirar no Redis
    const jobId = `job:${Date.now()}:${crypto.randomUUID()}`;
    const job = {
      id: jobId,
      type: payload.type,
      data: payload.data,
      priority: payload.priority || 5,
      status: 'pending',
      createdAt: new Date().toISOString(),
      scheduledFor: payload.scheduledFor || new Date().toISOString(),
      attempts: 0,
      maxAttempts: 3,
    };

    // Usar Redis List para fila
    await redis.lpush('jobs:pending', JSON.stringify(job));

    // Tamb√©m salvar em hash para lookup
    await redis.hset('jobs:all', jobId, JSON.stringify(job));

    // Set expiration (7 dias)
    await redis.expire(`jobs:all:${jobId}`, 7 * 24 * 60 * 60);

    console.log('‚úÖ Job enqueued:', jobId);

    return new Response(
      JSON.stringify({
        success: true,
        jobId,
        message: 'Job enqueued successfully'
      }),
      {
        headers: { 'Content-Type': 'application/json' },
        status: 200
      }
    );

  } catch (error) {
    console.error('‚ùå Error enqueueing job:', error);
    
    return new Response(
      JSON.stringify({
        success: false,
        error: error.message
      }),
      {
        headers: { 'Content-Type': 'application/json' },
        status: 500
      }
    );
  }
});
```

#### 1.3 Configurar pg_cron para chamar Edge Function

```sql
-- No Supabase SQL Editor

-- Fun√ß√£o helper para chamar Edge Function
CREATE OR REPLACE FUNCTION enqueue_job_via_edge_function(
  job_type TEXT,
  job_data JSONB,
  priority INT DEFAULT 5
)
RETURNS JSONB
LANGUAGE plpgsql
AS $$
DECLARE
  result JSONB;
  edge_function_url TEXT;
  cron_secret TEXT;
BEGIN
  -- URLs da Edge Function (configurar no Supabase Settings)
  edge_function_url := current_setting('app.edge_function_url', true);
  cron_secret := current_setting('app.cron_secret', true);
  
  -- Se n√£o configurado, usar valores padr√£o
  IF edge_function_url IS NULL THEN
    edge_function_url := 'https://zpdartuyaergbxmbmtur.supabase.co/functions/v1/enqueue-job';
  END IF;
  
  IF cron_secret IS NULL THEN
    cron_secret := 'e096742e-7b6d-4b6a-b987-41d533adbd50';
  END IF;

  -- Chamar Edge Function via http_request
  SELECT content::JSONB INTO result
  FROM http((
    'POST',
    edge_function_url,
    ARRAY[
      http_header('Content-Type', 'application/json'),
      http_header('Authorization', 'Bearer ' || cron_secret)
    ],
    'application/json',
    jsonb_build_object(
      'type', job_type,
      'data', job_data,
      'priority', priority
    )::TEXT
  )::http_request);

  RETURN result;
END;
$$;

-- ============================================
-- CRON JOBS
-- ============================================

-- 1. Processar mensagens pendentes (a cada 5 minutos)
SELECT cron.schedule(
  'process-pending-messages',
  '*/5 * * * *',  -- A cada 5 minutos
  $$
    SELECT enqueue_job_via_edge_function(
      'process-messages',
      jsonb_build_object(
        'limit', 50,
        'maxAge', '5 minutes'
      ),
      1  -- Alta prioridade
    );
  $$
);

-- 2. Limpeza de dados antigos (diariamente √†s 2am)
SELECT cron.schedule(
  'cleanup-old-data',
  '0 2 * * *',  -- 2am todos os dias
  $$
    SELECT enqueue_job_via_edge_function(
      'cleanup-data',
      jsonb_build_object(
        'olderThan', '30 days',
        'tables', ARRAY['messages', 'conversations']
      ),
      5  -- Prioridade normal
    );
  $$
);

-- 3. Sincronizar dados UAZAPI (a cada hora)
SELECT cron.schedule(
  'sync-uazapi',
  '0 * * * *',  -- A cada hora
  $$
    SELECT enqueue_job_via_edge_function(
      'sync-uazapi',
      jsonb_build_object(
        'syncType', 'incremental'
      ),
      3  -- Prioridade alta
    );
  $$
);

-- 4. Gerar relat√≥rios (segunda-feira √†s 8am)
SELECT cron.schedule(
  'weekly-reports',
  '0 8 * * 1',  -- Segunda-feira 8am
  $$
    SELECT enqueue_job_via_edge_function(
      'generate-reports',
      jsonb_build_object(
        'reportType', 'weekly',
        'recipients', ARRAY['admin@falachefe.app.br']
      ),
      7  -- Prioridade baixa
    );
  $$
);
```

#### 1.4 API Route no Vercel para processar fila

**Arquivo**: `src/app/api/cron/process-queue/route.ts`

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL!,
  token: process.env.UPSTASH_REDIS_REST_TOKEN!,
});

interface Job {
  id: string;
  type: string;
  data: any;
  priority: number;
  status: string;
  createdAt: string;
  scheduledFor: string;
  attempts: number;
  maxAttempts: number;
}

export async function POST(request: NextRequest) {
  try {
    // Validar secret
    const authHeader = request.headers.get('authorization');
    if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    console.log('üîÑ Processing job queue...');

    // Processar at√© 10 jobs por execu√ß√£o
    const maxJobs = 10;
    const processedJobs: string[] = [];
    const errors: any[] = [];

    for (let i = 0; i < maxJobs; i++) {
      // Pop job da fila (FIFO)
      const jobString = await redis.rpop<string>('jobs:pending');
      
      if (!jobString) {
        console.log('üì≠ Queue empty');
        break;
      }

      const job: Job = JSON.parse(jobString);
      
      console.log(`üì® Processing job ${job.id} (${job.type})`);

      try {
        // Executar job baseado no tipo
        await executeJob(job);

        // Marcar como conclu√≠do
        await redis.hset('jobs:all', job.id, JSON.stringify({
          ...job,
          status: 'completed',
          completedAt: new Date().toISOString()
        }));

        processedJobs.push(job.id);
        console.log(`‚úÖ Job ${job.id} completed`);

      } catch (error) {
        console.error(`‚ùå Job ${job.id} failed:`, error);

        // Incrementar tentativas
        job.attempts += 1;

        if (job.attempts < job.maxAttempts) {
          // Recolocar na fila (com backoff)
          console.log(`üîÑ Retrying job ${job.id} (attempt ${job.attempts})`);
          
          await redis.lpush('jobs:pending', JSON.stringify({
            ...job,
            status: 'retry'
          }));
        } else {
          // Marcar como falho
          console.log(`üíÄ Job ${job.id} failed permanently`);
          
          await redis.hset('jobs:all', job.id, JSON.stringify({
            ...job,
            status: 'failed',
            failedAt: new Date().toISOString(),
            error: error instanceof Error ? error.message : 'Unknown error'
          }));
        }

        errors.push({
          jobId: job.id,
          error: error instanceof Error ? error.message : 'Unknown error'
        });
      }
    }

    return NextResponse.json({
      success: true,
      processed: processedJobs.length,
      errors: errors.length,
      details: {
        processedJobs,
        errors
      }
    });

  } catch (error) {
    console.error('‚ùå Error processing queue:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}

// Executar job baseado no tipo
async function executeJob(job: Job): Promise<void> {
  switch (job.type) {
    case 'process-messages':
      await processMessages(job.data);
      break;
    
    case 'cleanup-data':
      await cleanupOldData(job.data);
      break;
    
    case 'sync-uazapi':
      await syncUAZAPI(job.data);
      break;
    
    case 'generate-reports':
      await generateReports(job.data);
      break;
    
    default:
      throw new Error(`Unknown job type: ${job.type}`);
  }
}

// Implementa√ß√µes dos handlers
async function processMessages(data: any): Promise<void> {
  // Processar mensagens pendentes
  console.log('Processing messages:', data);
  // Implementar l√≥gica
}

async function cleanupOldData(data: any): Promise<void> {
  // Limpar dados antigos
  console.log('Cleaning up old data:', data);
  // Implementar l√≥gica
}

async function syncUAZAPI(data: any): Promise<void> {
  // Sincronizar com UAZAPI
  console.log('Syncing UAZAPI:', data);
  // Implementar l√≥gica
}

async function generateReports(data: any): Promise<void> {
  // Gerar relat√≥rios
  console.log('Generating reports:', data);
  // Implementar l√≥gica
}
```

#### 1.5 Configurar Vercel Cron para processar fila

**Arquivo**: `vercel.json`

```json
{
  "crons": [
    {
      "path": "/api/cron/process-queue",
      "schedule": "*/5 * * * *"
    }
  ]
}
```

---

### Op√ß√£o 2: pg_cron ‚Üí Webhook Direto ‚Üí Vercel (ALTERNATIVA)

```sql
-- Fun√ß√£o para chamar webhook Vercel diretamente
CREATE OR REPLACE FUNCTION trigger_vercel_cron(
  endpoint TEXT,
  payload JSONB DEFAULT '{}'::JSONB
)
RETURNS JSONB
LANGUAGE plpgsql
AS $$
DECLARE
  result JSONB;
  vercel_url TEXT;
  cron_secret TEXT;
BEGIN
  vercel_url := 'https://falachefe.app.br' || endpoint;
  cron_secret := current_setting('app.cron_secret', true);

  SELECT content::JSONB INTO result
  FROM http((
    'POST',
    vercel_url,
    ARRAY[
      http_header('Content-Type', 'application/json'),
      http_header('Authorization', 'Bearer ' || cron_secret)
    ],
    'application/json',
    payload::TEXT
  )::http_request);

  RETURN result;
END;
$$;

-- Exemplo de uso
SELECT cron.schedule(
  'direct-webhook',
  '*/10 * * * *',
  $$
    SELECT trigger_vercel_cron(
      '/api/cron/process-messages',
      jsonb_build_object('limit', 50)
    );
  $$
);
```

---

## üìä COMPARA√á√ÉO DE OP√á√ïES

| Aspecto | Vercel Cron | Supabase pg_cron + Edge Function | Supabase pg_cron ‚Üí Webhook |
|---------|-------------|----------------------------------|----------------------------|
| **Confiabilidade** | M√©dia | Alta | Alta |
| **Timeout** | 10-300s | Configur√°vel | Configur√°vel |
| **Cold Start** | Sim | M√≠nimo | Sim (Vercel) |
| **Custo** | Serverless time | Inclu√≠do no Supabase | Serverless time |
| **Retry** | Manual | Autom√°tico (Redis) | Manual |
| **Debugging** | Dif√≠cil | F√°cil (logs Supabase) | M√©dio |
| **Complexidade** | Baixa | M√©dia | Baixa |
| **Flexibilidade** | Baixa | Alta | M√©dia |

**Recomenda√ß√£o**: Op√ß√£o 1 (pg_cron + Edge Function + Redis)

---

## ‚úÖ VANTAGENS DA SOLU√á√ÉO

### 1. Confiabilidade
```yaml
Supabase pg_cron:
  ‚úÖ N√£o depende de cold starts
  ‚úÖ Execu√ß√£o garantida
  ‚úÖ Logs persistentes
  ‚úÖ Retry configur√°vel
```

### 2. Flexibilidade
```yaml
Sistema de Filas:
  ‚úÖ Prioriza√ß√£o de jobs
  ‚úÖ Rate limiting
  ‚úÖ Scheduling avan√ßado
  ‚úÖ Retry autom√°tico
  ‚úÖ Dead letter queue
```

### 3. Custo
```yaml
Custos:
  ‚úÖ Supabase pg_cron: GR√ÅTIS (inclu√≠do)
  ‚úÖ Edge Functions: GR√ÅTIS at√© 500k req/m√™s
  ‚úÖ Upstash Redis: GR√ÅTIS at√© 10k commands/day
  ‚úÖ Vercel: Apenas processamento (n√£o cron)
  
Total: ~$0 para volume m√©dio
```

### 4. Monitoramento
```yaml
Visibilidade:
  ‚úÖ Logs Supabase (Edge Functions)
  ‚úÖ Status jobs no Redis
  ‚úÖ M√©tricas Vercel (processamento)
  ‚úÖ Hist√≥rico no PostgreSQL
```

---

## üöÄ CASOS DE USO

### 1. Processar Mensagens em Lote

```sql
-- Agendar processamento a cada 10 minutos
SELECT cron.schedule(
  'batch-messages',
  '*/10 * * * *',
  $$
    SELECT enqueue_job_via_edge_function(
      'process-batch',
      jsonb_build_object(
        'maxMessages', 100,
        'timeout', '120s'
      )
    );
  $$
);
```

### 2. Backup Autom√°tico

```sql
-- Backup di√°rio √†s 3am
SELECT cron.schedule(
  'daily-backup',
  '0 3 * * *',
  $$
    SELECT enqueue_job_via_edge_function(
      'backup-data',
      jsonb_build_object(
        'tables', ARRAY['users', 'conversations', 'messages'],
        'destination', 's3://backups/'
      ),
      9  -- Baixa prioridade
    );
  $$
);
```

### 3. Notifica√ß√µes Agendadas

```sql
-- Verificar notifica√ß√µes pendentes a cada 15min
SELECT cron.schedule(
  'pending-notifications',
  '*/15 * * * *',
  $$
    SELECT enqueue_job_via_edge_function(
      'send-notifications',
      jsonb_build_object(
        'channels', ARRAY['email', 'whatsapp'],
        'pending', true
      ),
      2  -- Alta prioridade
    );
  $$
);
```

### 4. Sincroniza√ß√£o com APIs

```sql
-- Sincronizar com UAZAPI a cada 30min
SELECT cron.schedule(
  'sync-whatsapp',
  '*/30 * * * *',
  $$
    SELECT enqueue_job_via_edge_function(
      'sync-external-api',
      jsonb_build_object(
        'api', 'uazapi',
        'syncType', 'incremental'
      )
    );
  $$
);
```

---

## üîç MONITORAMENTO E DEBUG

### Ver Jobs Agendados

```sql
-- Listar todos os cron jobs
SELECT 
  jobid,
  schedule,
  command,
  nodename,
  nodeport,
  database,
  username,
  active,
  jobname
FROM cron.job
ORDER BY jobid;

-- Ver hist√≥rico de execu√ß√µes
SELECT 
  jobid,
  runid,
  job_pid,
  database,
  username,
  command,
  status,
  return_message,
  start_time,
  end_time
FROM cron.job_run_details
ORDER BY start_time DESC
LIMIT 20;
```

### Monitorar Fila Redis

```typescript
// Script helper
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL!,
  token: process.env.UPSTASH_REDIS_REST_TOKEN!,
});

async function monitorQueue() {
  // Total de jobs pendentes
  const pendingCount = await redis.llen('jobs:pending');
  
  // Jobs por status
  const allJobs = await redis.hgetall('jobs:all');
  const stats = {
    pending: 0,
    processing: 0,
    completed: 0,
    failed: 0,
  };
  
  for (const [id, jobString] of Object.entries(allJobs)) {
    const job = JSON.parse(jobString as string);
    stats[job.status]++;
  }
  
  console.log('üìä Queue Stats:', {
    pendingCount,
    ...stats
  });
}
```

---

## üìã CHECKLIST DE IMPLEMENTA√á√ÉO

### Supabase
- [ ] Habilitar extens√£o `pg_cron`
- [ ] Habilitar extens√£o `http` (para requisi√ß√µes)
- [ ] Criar fun√ß√£o `enqueue_job_via_edge_function`
- [ ] Configurar vari√°veis (`app.edge_function_url`, `app.cron_secret`)
- [ ] Criar cron jobs necess√°rios

### Edge Function
- [ ] Criar fun√ß√£o `enqueue-job` no Supabase
- [ ] Configurar secrets (UPSTASH_REDIS_REST_URL, CRON_SECRET)
- [ ] Deploy da fun√ß√£o
- [ ] Testar endpoint

### Redis
- [ ] Configurar estrutura de filas
- [ ] Implementar TTL para jobs
- [ ] Configurar monitoramento

### Vercel
- [ ] Criar `/api/cron/process-queue` route
- [ ] Configurar `vercel.json` com cron
- [ ] Implementar handlers para cada tipo de job
- [ ] Adicionar logging adequado
- [ ] Testar localmente

### Seguran√ßa
- [ ] Configurar `CRON_SECRET` forte
- [ ] Validar authorization em todos endpoints
- [ ] Rate limiting
- [ ] Valida√ß√£o de payload

---

## üéì CONCLUS√ÉO

### ‚úÖ RECOMENDA√á√ÉO

**USE Supabase pg_cron + Edge Functions + Upstash Redis**

**Por qu√™?**:
1. ‚úÖ Mais confi√°vel que Vercel Cron
2. ‚úÖ Sem cold starts
3. ‚úÖ Retry autom√°tico
4. ‚úÖ Custo zero (volume m√©dio)
5. ‚úÖ F√°cil de monitorar
6. ‚úÖ Escal√°vel

### üìä Custo Comparativo

```
Solu√ß√£o Atual (Vercel Cron):
  ‚Ä¢ Serverless executions: $X/m√™s
  ‚Ä¢ Build time: Sim
  ‚Ä¢ Limita√ß√µes: Sim

Solu√ß√£o Nova (Supabase + Redis):
  ‚Ä¢ Supabase pg_cron: $0
  ‚Ä¢ Edge Functions: $0 (at√© 500k/m√™s)
  ‚Ä¢ Upstash Redis: $0 (at√© 10k/dia)
  ‚Ä¢ Vercel apenas processa fila: Menor uso
  
Economia: $10-30/m√™s + Mais confi√°vel
```

---

**Status**: ‚úÖ Solu√ß√£o vi√°vel e recomendada  
**Complexidade**: M√©dia (vale o investimento)  
**ROI**: Positivo (economia + confiabilidade)


