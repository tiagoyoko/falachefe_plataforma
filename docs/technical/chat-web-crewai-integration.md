# üåê Integra√ß√£o do Chat Web com CrewAI

## üìã Vis√£o Geral

Este documento descreve a integra√ß√£o completa entre a interface web de chat e os agentes CrewAI no projeto Falachefe.

## üèóÔ∏è Arquitetura

```mermaid
graph TB
    A[Interface Web /chat] -->|1. POST| B[/api/chat]
    B -->|2. POST| C[/api/crewai/process]
    C -->|3. spawn| D[webhook_processor.py]
    D -->|4. kickoff| E[FalachefeCrew]
    E -->|5. processa| F[Agentes CrewAI]
    F -->|6. retorna| E
    E -->|7. resposta| D
    D -->|8. JSON| C
    C -->|9. JSON| B
    B -->|10. JSON| A
    
    style A fill:#e1f5ff
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style D fill:#4fc3f7
    style E fill:#29b6f6
    style F fill:#039be5
```

## üìÅ Componentes

### 1. Interface Web (`/src/app/chat/page.tsx`)

**Localiza√ß√£o**: `/chat`

**Caracter√≠sticas**:
- Interface moderna com suporte a Markdown
- Renderiza√ß√£o de c√≥digo, tabelas, listas
- Indicadores de carregamento
- Tratamento de erros
- Hist√≥rico de conversa√ß√£o
- C√≥pia de mensagens

**Hook**: `useAgentChat` (`/src/hooks/use-agent-chat.ts`)

```typescript
const { 
  messages,        // Hist√≥rico de mensagens
  isLoading,       // Estado de processamento
  error,           // Mensagem de erro
  conversationId,  // ID da conversa
  sendMessage,     // Enviar mensagem
  clearChat,       // Limpar hist√≥rico
  retryLastMessage // Tentar novamente
} = useAgentChat(session?.user?.id);
```

### 2. Endpoint Web Chat (`/src/app/api/chat/route.ts`)

**M√©todo**: `POST /api/chat`

**Request Body**:
```json
{
  "message": "Ol√°! Qual √© o meu saldo?",
  "userId": "user-123",
  "conversationId": "conv-456",
  "includeUserProfile": true,
  "forceToolUse": true
}
```

**Response**:
```json
{
  "success": true,
  "content": "Seu saldo atual √© R$ 1.234,56...",
  "metadata": {
    "processing_time_ms": 2500,
    "conversationId": "conv-456",
    "source": "web-chat",
    "timestamp": "2025-10-11T..."
  }
}
```

**Valida√ß√µes**:
- ‚úÖ Mensagem n√£o vazia
- ‚úÖ UserId presente
- ‚úÖ Formato JSON v√°lido

### 3. Endpoint CrewAI (`/src/app/api/crewai/process/route.ts`)

**M√©todo**: `POST /api/crewai/process`

**Request Body**:
```json
{
  "message": "Qual √© o meu saldo?",
  "userId": "user-123",
  "phoneNumber": "",
  "context": {
    "source": "web-chat",
    "conversationId": "conv-456",
    "includeUserProfile": true
  }
}
```

**Processo**:
1. Valida entrada
2. Spawns processo Python
3. Executa `webhook_processor.py`
4. Aguarda resposta (timeout 60s)
5. Retorna JSON estruturado

### 4. Processador CrewAI (`webhook_processor.py`)

**Localiza√ß√£o**: `/crewai-projects/falachefe_crew/webhook_processor.py`

**Fluxo**:
```python
def process_webhook_message(inputs):
    # 1. Valida inputs
    validate_inputs(inputs)
    
    # 2. Inicializa FalachefeCrew
    crew = FalachefeCrew()
    
    # 3. Executa agentes
    result = crew.kickoff(inputs={
        'user_message': inputs['user_message'],
        'user_id': inputs['user_id'],
        'context': inputs.get('context', {})
    })
    
    # 4. Retorna resposta
    return {
        'success': True,
        'response': result.output,
        'metadata': {...}
    }
```

## üîÑ Fluxo Completo

### Cen√°rio: Usu√°rio pergunta sobre saldo

1. **Usu√°rio** digita na interface web:
   ```
   "Qual √© o meu saldo atual?"
   ```

2. **Interface Web** (`ChatPage`) chama hook:
   ```typescript
   sendMessage("Qual √© o meu saldo atual?")
   ```

3. **Hook** (`useAgentChat`) faz requisi√ß√£o:
   ```typescript
   fetch('/api/chat', {
     method: 'POST',
     body: JSON.stringify({
       message: "Qual √© o meu saldo atual?",
       userId: "user-123",
       conversationId: "conv-456"
     })
   })
   ```

4. **Endpoint `/api/chat`** valida e encaminha:
   ```typescript
   fetch('/api/crewai/process', {
     method: 'POST',
     body: JSON.stringify({
       message: "Qual √© o meu saldo atual?",
       userId: "user-123",
       context: { source: 'web-chat', ... }
     })
   })
   ```

5. **Endpoint `/api/crewai/process`** executa Python:
   ```typescript
   spawn('python3', ['webhook_processor.py'], {
     stdin: JSON.stringify(inputs)
   })
   ```

6. **Python** inicializa e executa crew:
   ```python
   crew = FalachefeCrew()
   result = crew.kickoff(inputs={...})
   ```

7. **FalachefeCrew** orquestra agentes:
   - FinancialAgent analisa pergunta
   - Consulta ferramenta de saldo
   - Formata resposta

8. **Resposta** retorna pela stack:
   ```
   Python ‚Üí /api/crewai/process ‚Üí /api/chat ‚Üí Hook ‚Üí Interface
   ```

9. **Usu√°rio** v√™ resposta formatada:
   ```markdown
   ## Seu Saldo Atual
   
   üí∞ **Saldo dispon√≠vel**: R$ 1.234,56
   
   - Entradas: R$ 5.000,00
   - Sa√≠das: R$ 3.765,44
   ```

## üß™ Como Testar

### Teste 1: Localmente

```bash
# Terminal 1: Inicie o servidor
npm run dev

# Terminal 2: Execute o teste
./scripts/testing/test-web-chat.sh local
```

### Teste 2: Via Interface Web

1. Abra: `http://localhost:3000/chat`
2. Fa√ßa login
3. Digite uma mensagem
4. Aguarde resposta (~10-30s)

### Teste 3: Via cURL

```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Qual √© o meu saldo?",
    "userId": "test-user",
    "conversationId": "test-conv",
    "includeUserProfile": true
  }'
```

## üöÄ Deploy

### ‚ö†Ô∏è Limita√ß√µes na Vercel

A Vercel **N√ÉO suporta Python** por padr√£o no runtime serverless. Portanto:

‚ùå **N√£o funciona em produ√ß√£o na Vercel**:
- `/api/crewai/process` falha ao tentar executar Python
- `spawn('python3')` retorna erro

‚úÖ **Funciona localmente**:
- Ambiente de desenvolvimento tem Python instalado
- Tudo funciona perfeitamente em `npm run dev`

### Solu√ß√µes para Produ√ß√£o

#### Op√ß√£o A: Deploy CrewAI Separadamente (Recomendado)

**Servi√ßos Recomendados**:
- Railway.app (mais f√°cil para Python)
- Render.com (suporte nativo a Python)
- Google Cloud Run (containerizado)
- Heroku (plataforma madura)

**Arquitetura**:
```
Interface Web (Vercel)
    ‚Üì
/api/chat (Vercel)
    ‚Üì
CrewAI Service (Railway)
    ‚Üì
FalachefeCrew (Python)
```

**Mudan√ßa Necess√°ria**:
```typescript
// src/app/api/chat/route.ts
const crewAIUrl = process.env.CREWAI_SERVICE_URL || 
                  'https://falachefe-crewai.railway.app/process';
```

#### Op√ß√£o B: Vercel Python Runtime

Converter para Vercel Functions (Beta):

```python
# api-python/chat.py
from http.server import BaseHTTPRequestHandler
import json

class handler(BaseHTTPRequestHandler):
    def do_POST(self):
        # Processar com CrewAI
        ...
```

```json
// vercel.json
{
  "functions": {
    "api-python/chat.py": {
      "runtime": "python3.9"
    }
  }
}
```

#### Op√ß√£o C: Fila Ass√≠ncrona (Upstash QStash)

Arquitetura desacoplada:
```
/api/chat ‚Üí Upstash QStash ‚Üí Worker Python ‚Üí Callback
```

## üìä Performance

### M√©tricas Esperadas

| M√©trica | Local | Produ√ß√£o (Railway) |
|---------|-------|-------------------|
| Lat√™ncia total | 10-30s | 15-40s |
| /api/chat | <100ms | <200ms |
| /api/crewai/process | 10-30s | 15-40s |
| Python spawn | <500ms | <1s |
| CrewAI processing | 10-25s | 15-35s |

### Otimiza√ß√µes

1. **Cache de Respostas**:
   ```typescript
   // Implementar cache Redis para perguntas comuns
   const cached = await redis.get(`chat:${messageHash}`);
   if (cached) return cached;
   ```

2. **Streaming de Resposta**:
   ```typescript
   // Implementar Server-Sent Events (SSE)
   // para streaming da resposta do agente
   ```

3. **Timeout Configur√°vel**:
   ```typescript
   const CREWAI_TIMEOUT = parseInt(
     process.env.CREWAI_TIMEOUT_MS || '60000'
   );
   ```

## üîç Debugging

### Logs Importantes

**Interface Web** (Console do navegador):
```
ü§ñ Agent Message: {...}
üì® API Response: {...}
```

**Endpoint /api/chat** (Vercel Logs):
```
üåê Web chat message received: {...}
ü§ñ Calling CrewAI endpoint: {...}
‚úÖ CrewAI response received: {...}
```

**Endpoint /api/crewai/process** (Vercel Logs):
```
ü§ñ Processing message with CrewAI: {...}
üêç Executing Python script: {...}
[Python] üì• Processing message: ...
[Python] üöÄ Initializing FalachefeCrew...
[Python] ‚úÖ Crew executed successfully
‚úÖ CrewAI processing completed: {...}
```

### Problemas Comuns

#### 1. "Erro ao processar mensagem"

**Causa**: Endpoint CrewAI n√£o est√° respondendo

**Solu√ß√£o**:
```bash
# Verificar se servidor est√° rodando
curl http://localhost:3000/api/crewai/process

# Verificar logs
tail -f ~/.npm/_logs/*.log
```

#### 2. "Python n√£o dispon√≠vel"

**Causa**: Tentando executar em produ√ß√£o (Vercel)

**Solu√ß√£o**: Deploy CrewAI separadamente (ver Op√ß√£o A acima)

#### 3. Timeout ap√≥s 60s

**Causa**: CrewAI demorou muito para processar

**Solu√ß√£o**:
```typescript
// Aumentar timeout
const timeout = setTimeout(() => {
  python.kill('SIGTERM');
}, 120000); // 2 minutos
```

## üìö Refer√™ncias

- [CrewAI Documentation](https://docs.crewai.com/)
- [Next.js API Routes](https://nextjs.org/docs/api-routes/introduction)
- [Vercel Functions](https://vercel.com/docs/functions)
- [Railway Python Deploy](https://docs.railway.app/guides/python)

## üéØ Checklist de Implementa√ß√£o

- [x] Criar endpoint `/api/chat`
- [x] Implementar hook `useAgentChat`
- [x] Criar interface web de chat
- [x] Integrar com `/api/crewai/process`
- [x] Adicionar valida√ß√µes
- [x] Implementar tratamento de erros
- [x] Criar testes automatizados
- [x] Documentar fluxo completo
- [ ] Deploy CrewAI em ambiente separado
- [ ] Implementar cache de respostas
- [ ] Adicionar streaming de resposta (SSE)
- [ ] Implementar analytics/m√©tricas
- [ ] Adicionar rate limiting
- [ ] Implementar hist√≥rico persistente

## üìù Notas de Desenvolvimento

**Data de Cria√ß√£o**: 11/10/2025  
**√öltima Atualiza√ß√£o**: 11/10/2025  
**Status**: ‚úÖ Implementado (funciona localmente)  
**Produ√ß√£o**: ‚ö†Ô∏è Requer deploy Python separado

